{"title":"GPT-3","description":"Task agnostic language models. ","primaryUsecase":"To detect stress in building occupants using sensors from handrails. \n\nNotes: User studies (different order of questions, phrasing of questions, etc.) -> How do I get people to think critically. \n\n","antiGoals":[],"stakeholderImpacts":[{"stakeholder":"Building Occupants","impact":"Not sure if people would understand this, are computer scientists used to thinking about power structures? \n\nSuggested groups of people who are commonly impacted?  "},{"stakeholder":"Landlords","impact":"Getting at different things: how can people use this model in ways that is not intended -> how does it impact different subsets of people \n\nPrime them with a story or something. \"imagine that people going to benefit from this\" who are the people who are going to be negatively affectsd"}],"limitations":[{"type":"Repetition","description":"GPT-3 samples sometimes repeat themselves semantically at the document level, and can lose coherence over sufficiently long passages, contradict themselves, and occasionally contain non-sequitur sentences or paragraphs. Our release repository contains 500 unconditional, unfiltered 2048 token samples (CONTENT WARNING: GPT-3 was trained on arbitrary data from the web, so samples may contain offensive content and language)."},{"type":"Lack of world grounding","description":"GPT-3, like other large pretrained language models, is not grounded in other modalities of experience, such as video, real-world physical interaction, or human feedback, and thus lacks a large amount of context about the world."},{"type":"Predominantly English","description":"GPT-3 is trained largely on text in the English language, and is best suited for classifying, searching, summarizing, or generating such text. GPT-3 will by default perform worse on inputs that are different from the data distribution it is trained on, including non-English languages as well as specific dialects of English that are not as well-represented in training data."},{"type":"Interpretability & predictability","description":"The capacity to interpret or predict how GPT-3 will behave is very limited, a limitation common to most deep learning systems, especially in models of this scale."},{"type":"High variance on novel inputs","description":"GPT-3 is not necessarily well-calibrated in its predictions on novel inputs. This can be observed in the much higher variance in its performance as compared to that of humans on standard benchmarks."},{"type":"Creation date of training corpora","description":"The May 2020 version of GPT-3 was trained on a dataset created in November 2019, so has not been trained on any data more recent than that. The September 2020 version of the model was retrained to reflect data up to August 2020."},{"type":"Biases","description":"GPT-3, like all large language models trained on internet corpora, will generate stereotyped or prejudiced content. The model has the propensity to retain and magnify biases it inherited from any part of its training, from the datasets we selected to the training techniques we chose. This is concerning, since model bias could harm people in the relevant groups in different ways by entrenching existing stereotypes and producing demeaning portrayals amongst other potential harms. This issue is of special concern from a societal perspective, and is discussed along with other issues in the paper section on Broader Impacts."}],"ethicalConsiderations":[{"description":"The intended direct users of GPT-3 are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models."},{"description":"Given GPT-3’s limitations (described below), and the breadth and open-ended nature of GPT-3’s capabilities, we currently only support controlled access to and use of the model via the OpenAI API. Access and use are subject to OpenAI’s access approval process, API Usage Guidelines, and API Terms of Use, which are designed to prohibit the use of the API in a way that causes societal harm.\n\nWe review all use cases prior to onboarding to the API, review them again before customers move into production, and have systems in place to revoke access if necessary after moving to production. Additionally, we provide guidance to users on some of the potential safety risks they should attend to and related mitigations."},{"description":"Given its training data, GPT-3’s outputs and performance are more representative of internet-connected populations than those steeped in verbal, non-digital culture."},{"description":"The internet-connected population is more representative of developed countries, wealthy, younger, and male views, and is mostly U.S.-centric. Wealthier nations and populations in developed countries show higher internet penetration. The digital gender divide also shows fewer women represented online worldwide."},{"description":"Additionally, because different parts of the world have different levels of internet penetration and access, the dataset underrepresents less connected communities."}],"datasets":[{"name":"Custom Dataset","description":"The GPT-3 training dataset is composed of text posted to the internet, or of text uploaded to the internet (e.g., books). The internet data that it has been trained on and evaluated against to date includes: (1) a version of the CommonCrawl dataset, filtered based on similarity to high-quality reference corpora, (2) an expanded version of the Webtext dataset, (3) two internet-based book corpora, and (4) English-language Wikipedia."}],"performanceOverview":"GPT-3’s performance has been evaluated on a wide range of datasets in the task categories listed below, with each task evaluated in the few-shot, one-shot, and zero-shot settings.\n\n- Language Modeling, Cloze, and Completion Tasks\n- Closed Book Question Answering\n- Translation\n- Winograd-Style Tasks\n- Common Sense Reasoning Tasks\n- Reading Comprehension\n- SuperGLUE\n- Natural Language Inference\n- Synthetic and Qualitative Tasks\n\nSuch measures of performance depend on details of the benchmark and therefore won’t be the same as the performance of the model in a deployed system. Ultimately, performance of a deployed system depends on a number of factors, including the technology and how it is configured, the use case for the system, the context in which it is used, how people interact with the system, and how people interpret the system’s output.","performanceMetrics":[],"figures":[],"type":"Natural Language Processing","authors":[{"name":"Anonymous","contact":"Open.AI"},{"name":"Nate Lee","contact":"natelee@stanford.edu"}],"version":"vAICard","supportingLinks":[{"link":"https://github.com/openai/gpt-3/blob/master/model-card.md"},{"link":"https://arxiv.org/abs/2005.14165"},{"link":"https://github.com/openai/gpt-3/blob/master/175b_samples.jsonl"}],"license":"","inputs":[{"name":"Text"}],"outputs":[{"name":"Text"}],"showcase":[],"architectureDescription":"Generative Pretrained Transformer or “GPT”-style autoregressive language model with 175 billion parameters.","primaryGoal":"The intended direct users of GPT-3 are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models.","groupImpacts":[]}